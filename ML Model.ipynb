{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = combined_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGENCY IDENTIFIER</th>\n",
       "      <th>BIAS MOTIVATION</th>\n",
       "      <th>CITY</th>\n",
       "      <th>JUDICIAL DISTRICT</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>REGION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>020A</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>260900</td>\n",
       "      <td>Jul to Sep</td>\n",
       "      <td>West</td>\n",
       "      <td>AK</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>020A</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>260900</td>\n",
       "      <td>Jul to Sep</td>\n",
       "      <td>West</td>\n",
       "      <td>AK</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>020A</td>\n",
       "      <td>Highway/road/alley</td>\n",
       "      <td>260900</td>\n",
       "      <td>Jan to Mar</td>\n",
       "      <td>West</td>\n",
       "      <td>AK</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>020A</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>260900</td>\n",
       "      <td>Jan to Mar</td>\n",
       "      <td>West</td>\n",
       "      <td>AK</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AR0080300</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>GREEN FOREST</td>\n",
       "      <td>035W</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>2785</td>\n",
       "      <td>Jul to Sep</td>\n",
       "      <td>South</td>\n",
       "      <td>AR</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128727</td>\n",
       "      <td>WV0490100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>BUCKHANNON</td>\n",
       "      <td>430N</td>\n",
       "      <td>Bar/nightclub</td>\n",
       "      <td>5662</td>\n",
       "      <td>Oct to Dec</td>\n",
       "      <td>South</td>\n",
       "      <td>WV</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128728</td>\n",
       "      <td>WV0540100</td>\n",
       "      <td>Anti-Sexual Orientation</td>\n",
       "      <td>PARKERSBURG</td>\n",
       "      <td>435S</td>\n",
       "      <td>Highway/road/alley</td>\n",
       "      <td>30913</td>\n",
       "      <td>Jan to Mar</td>\n",
       "      <td>South</td>\n",
       "      <td>WV</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128729</td>\n",
       "      <td>WY0030100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>GILLETTE</td>\n",
       "      <td>450A</td>\n",
       "      <td>School--elementary/secondary</td>\n",
       "      <td>33218</td>\n",
       "      <td>Apr to Jun</td>\n",
       "      <td>West</td>\n",
       "      <td>WY</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128730</td>\n",
       "      <td>WY0030100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>GILLETTE</td>\n",
       "      <td>450A</td>\n",
       "      <td>School--elementary/secondary</td>\n",
       "      <td>33218</td>\n",
       "      <td>Apr to Jun</td>\n",
       "      <td>West</td>\n",
       "      <td>WY</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128731</td>\n",
       "      <td>WY0030100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>GILLETTE</td>\n",
       "      <td>450A</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>33218</td>\n",
       "      <td>Oct to Dec</td>\n",
       "      <td>West</td>\n",
       "      <td>WY</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128322 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGENCY IDENTIFIER          BIAS MOTIVATION          CITY  \\\n",
       "0              AK0010100                Anti-Race     ANCHORAGE   \n",
       "1              AK0010100                Anti-Race     ANCHORAGE   \n",
       "2              AK0010100                Anti-Race     ANCHORAGE   \n",
       "3              AK0010100                Anti-Race     ANCHORAGE   \n",
       "4              AR0080300                Anti-Race  GREEN FOREST   \n",
       "...                  ...                      ...           ...   \n",
       "128727         WV0490100                Anti-Race    BUCKHANNON   \n",
       "128728         WV0540100  Anti-Sexual Orientation   PARKERSBURG   \n",
       "128729         WY0030100                Anti-Race      GILLETTE   \n",
       "128730         WY0030100                Anti-Race      GILLETTE   \n",
       "128731         WY0030100                Anti-Race      GILLETTE   \n",
       "\n",
       "       JUDICIAL DISTRICT                      LOCATION  POPULATION  \\\n",
       "0                   020A                Residence/home      260900   \n",
       "1                   020A                Residence/home      260900   \n",
       "2                   020A            Highway/road/alley      260900   \n",
       "3                   020A                Residence/home      260900   \n",
       "4                   035W                Residence/home        2785   \n",
       "...                  ...                           ...         ...   \n",
       "128727              430N                 Bar/nightclub        5662   \n",
       "128728              435S            Highway/road/alley       30913   \n",
       "128729              450A  School--elementary/secondary       33218   \n",
       "128730              450A  School--elementary/secondary       33218   \n",
       "128731              450A                Residence/home       33218   \n",
       "\n",
       "           QUARTER REGION STATE  YEAR  \n",
       "0       Jul to Sep   West    AK  2000  \n",
       "1       Jul to Sep   West    AK  2000  \n",
       "2       Jan to Mar   West    AK  2000  \n",
       "3       Jan to Mar   West    AK  2000  \n",
       "4       Jul to Sep  South    AR  2000  \n",
       "...            ...    ...   ...   ...  \n",
       "128727  Oct to Dec  South    WV  2016  \n",
       "128728  Jan to Mar  South    WV  2016  \n",
       "128729  Apr to Jun   West    WY  2016  \n",
       "128730  Apr to Jun   West    WY  2016  \n",
       "128731  Oct to Dec   West    WY  2016  \n",
       "\n",
       "[128322 rows x 10 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2010, 2011, 2012,\n",
       "       2013, 2014, 2015, 2016])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.YEAR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdScalerByGroup(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> std.grps_ is not None\n",
    "        True\n",
    "        \"\"\"\n",
    "        # X may not be a pandas dataframe (e.g. a np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        mean_df = df.groupby(df.columns[0]).mean()\n",
    "        std_df = df.groupby(df.columns[0]).std()\n",
    "        \n",
    "        # A dictionary of means/standard-deviations for each column, for each group.\n",
    "        self.grps_ = [mean_df, std_df]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> out = std.transform(X)\n",
    "        >>> out.shape == (4, 2)\n",
    "        True\n",
    "        >>> np.isclose(out.abs(), 0.707107, atol=0.001).all().all()\n",
    "        True\n",
    "        \"\"\"\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "        \n",
    "        # X may not be a dataframe (e.g. np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        \n",
    "        grouped_mean = self.grps_[0]\n",
    "        grouped_std = self.grps_[1]\n",
    "        numerator = (df.set_index(df.columns[0])-grouped_mean.reindex(df[df.columns[0]])).reset_index()\n",
    "        z_score = (numerator.set_index(df.columns[0])/grouped_std.reindex(df[df.columns[0]])).reset_index()\n",
    "        return z_score.set_index(z_score.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value = temp.drop(columns=['BIAS MOTIVATION'])\n",
    "y_value = temp['BIAS MOTIVATION']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_value, y_value, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(titanic):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'titanic.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl = titanic_model(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> from sklearn.base import BaseEstimator\n",
    "    >>> isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "    True\n",
    "    >>> preds = pl.predict(data.drop('Survived', axis=1))\n",
    "    >>> ((preds == 0)|(preds == 1)).all()\n",
    "    True\n",
    "    \"\"\"    \n",
    "    def prefix(col):\n",
    "        col = col.iloc[:,0]\n",
    "        return np.array(col.str.split().str[:1].str[0]).reshape(-1,1)\n",
    "    \n",
    "    #name_feat = ['Name']\n",
    "    #name_tran = Pipeline([\n",
    "        #('title', FunctionTransformer(prefix, validate=False)),\n",
    "        #('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    #])\n",
    "\n",
    "#     p_feat = ['POPULATION']\n",
    "#     p_tran = Pipeline([\n",
    "#        ('standard unit', pp.StandardScaler())\n",
    "#     ])\n",
    "\n",
    "    cat_feat = ['AGENCY IDENTIFIER', 'CITY', 'JUDICIAL DISTRICT',\n",
    "       'LOCATION', 'POPULATION', 'QUARTER', 'REGION', 'STATE', 'YEAR']\n",
    "    cat_tran = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    pre = ColumnTransformer(transformers=[('cat', cat_tran, cat_feat)], remainder='passthrough')\n",
    "\n",
    "    comb = Pipeline([('preprocessor', pre), ('rfc', RandomForestClassifier(n_estimators=180,min_samples_leaf=3))])\n",
    "    comb.fit(x_train,y_train)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = titanic_model(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = p1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6716124809077024\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anti-Race                  28996\n",
       "Anti-Religion               2718\n",
       "Anti-Sexual Orientation      341\n",
       "Anti-Disability               26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(titanic):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'titanic.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl = titanic_model(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> from sklearn.base import BaseEstimator\n",
    "    >>> isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "    True\n",
    "    >>> preds = pl.predict(data.drop('Survived', axis=1))\n",
    "    >>> ((preds == 0)|(preds == 1)).all()\n",
    "    True\n",
    "    \"\"\"    \n",
    "    def prefix(col):\n",
    "        col = col.iloc[:,0]\n",
    "        return np.array(col.str.split().str[:1].str[0]).reshape(-1,1)\n",
    "    \n",
    "    #name_feat = ['Name']\n",
    "    #name_tran = Pipeline([\n",
    "        #('title', FunctionTransformer(prefix, validate=False)),\n",
    "        #('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    #])\n",
    "\n",
    "#     p_feat = ['POPULATION']\n",
    "#     p_tran = Pipeline([\n",
    "#        ('standard unit', pp.StandardScaler())\n",
    "#     ])\n",
    "\n",
    "    cat_feat = ['AGENCY IDENTIFIER', 'CITY', 'JUDICIAL DISTRICT',\n",
    "       'LOCATION', 'POPULATION', 'QUARTER', 'REGION', 'STATE', 'YEAR']\n",
    "    cat_tran = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    pre = ColumnTransformer(transformers=[('cat', cat_tran, cat_feat)], remainder='passthrough')\n",
    "\n",
    "    comb = Pipeline([('preprocessor', pre), ('rfc', KNeighborsClassifier())])\n",
    "    comb.fit(x_train,y_train)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = titanic_model(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = p1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6588323306630093\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(titanic):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'titanic.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl = titanic_model(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> from sklearn.base import BaseEstimator\n",
    "    >>> isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "    True\n",
    "    >>> preds = pl.predict(data.drop('Survived', axis=1))\n",
    "    >>> ((preds == 0)|(preds == 1)).all()\n",
    "    True\n",
    "    \"\"\"    \n",
    "    def prefix(col):\n",
    "        col = col.iloc[:,0]\n",
    "        return np.array(col.str.split().str[:1].str[0]).reshape(-1,1)\n",
    "    \n",
    "    #name_feat = ['Name']\n",
    "    #name_tran = Pipeline([\n",
    "        #('title', FunctionTransformer(prefix, validate=False)),\n",
    "        #('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    #])\n",
    "\n",
    "#     p_feat = ['POPULATION']\n",
    "#     p_tran = Pipeline([\n",
    "#        ('standard unit', pp.StandardScaler())\n",
    "#     ])\n",
    "\n",
    "    cat_feat = ['AGENCY IDENTIFIER', 'CITY', 'JUDICIAL DISTRICT',\n",
    "       'LOCATION', 'POPULATION', 'QUARTER', 'REGION', 'STATE', 'YEAR']\n",
    "    cat_tran = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    pre = ColumnTransformer(transformers=[('cat', cat_tran, cat_feat)], remainder='passthrough')\n",
    "\n",
    "    comb = Pipeline([('preprocessor', pre), ('rfc', GaussianNB())])\n",
    "    comb.fit(x_train,y_train)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
