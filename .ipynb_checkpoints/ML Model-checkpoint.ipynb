{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.preprocessing as pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = combined_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGENCY IDENTIFIER    0\n",
       "BIAS MOTIVATION      0\n",
       "CITY                 0\n",
       "JUDICIAL DISTRICT    0\n",
       "LOCATION             0\n",
       "POPULATION           0\n",
       "QUARTER              0\n",
       "REGION               0\n",
       "STATE                0\n",
       "YEAR                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdScalerByGroup(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> std.grps_ is not None\n",
    "        True\n",
    "        \"\"\"\n",
    "        # X may not be a pandas dataframe (e.g. a np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        mean_df = df.groupby(df.columns[0]).mean()\n",
    "        std_df = df.groupby(df.columns[0]).std()\n",
    "        \n",
    "        # A dictionary of means/standard-deviations for each column, for each group.\n",
    "        self.grps_ = [mean_df, std_df]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> out = std.transform(X)\n",
    "        >>> out.shape == (4, 2)\n",
    "        True\n",
    "        >>> np.isclose(out.abs(), 0.707107, atol=0.001).all().all()\n",
    "        True\n",
    "        \"\"\"\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "        \n",
    "        # X may not be a dataframe (e.g. np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        \n",
    "        grouped_mean = self.grps_[0]\n",
    "        grouped_std = self.grps_[1]\n",
    "        numerator = (df.set_index(df.columns[0])-grouped_mean.reindex(df[df.columns[0]])).reset_index()\n",
    "        z_score = (numerator.set_index(df.columns[0])/grouped_std.reindex(df[df.columns[0]])).reset_index()\n",
    "        return z_score.set_index(z_score.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value = temp.drop(columns=['BIAS MOTIVATION'])\n",
    "y_value = temp['BIAS MOTIVATION']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_value, y_value, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(titanic):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'titanic.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl = titanic_model(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> from sklearn.base import BaseEstimator\n",
    "    >>> isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "    True\n",
    "    >>> preds = pl.predict(data.drop('Survived', axis=1))\n",
    "    >>> ((preds == 0)|(preds == 1)).all()\n",
    "    True\n",
    "    \"\"\"    \n",
    "    def prefix(col):\n",
    "        col = col.iloc[:,0]\n",
    "        return np.array(col.str.split().str[:1].str[0]).reshape(-1,1)\n",
    "    \n",
    "    #name_feat = ['Name']\n",
    "    #name_tran = Pipeline([\n",
    "        #('title', FunctionTransformer(prefix, validate=False)),\n",
    "        #('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    #])\n",
    "\n",
    "#     p_feat = ['POPULATION']\n",
    "#     p_tran = Pipeline([\n",
    "#        ('standard unit', pp.StandardScaler())\n",
    "#     ])\n",
    "\n",
    "    cat_feat = ['AGENCY IDENTIFIER', 'CITY', 'JUDICIAL DISTRICT',\n",
    "       'LOCATION', 'POPULATION', 'QUARTER', 'REGION', 'STATE', 'YEAR']\n",
    "    cat_tran = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    pre = ColumnTransformer(transformers=[('cat', cat_tran, cat_feat)], remainder='passthrough')\n",
    "\n",
    "    comb = Pipeline([('preprocessor', pre), ('rfc', RandomForestClassifier(n_estimators=180,min_samples_leaf=3))])\n",
    "    comb.fit(x_train,y_train)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = titanic_model(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = p1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6768492253982108\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anti-Race                  20355\n",
       "Anti-Religion               5961\n",
       "Anti-Sexual Orientation     5535\n",
       "Anti-Disability              203\n",
       "Anti-Gender                   27\n",
       "Name: BIAS MOTIVATION, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
