{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('ML_Data/23441-0002-Data.dta', columns=['ORI','CITY','STATECOD','REGION','JUDDIST','POP1','MASTERYR','BIASMO1','LOCCOD1','QUARTER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with NaN's \n",
    "df = df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORI</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATECOD</th>\n",
       "      <th>REGION</th>\n",
       "      <th>JUDDIST</th>\n",
       "      <th>POP1</th>\n",
       "      <th>MASTERYR</th>\n",
       "      <th>BIASMO1</th>\n",
       "      <th>LOCCOD1</th>\n",
       "      <th>QUARTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "      <td>West</td>\n",
       "      <td>020A</td>\n",
       "      <td>276109</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Black</td>\n",
       "      <td>Highway/road/alley</td>\n",
       "      <td>Apr to Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "      <td>West</td>\n",
       "      <td>020A</td>\n",
       "      <td>276109</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Am Indian</td>\n",
       "      <td>Other/unknown</td>\n",
       "      <td>Jul to Sep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "      <td>West</td>\n",
       "      <td>020A</td>\n",
       "      <td>276109</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Am Indian</td>\n",
       "      <td>Highway/road/alley</td>\n",
       "      <td>Jul to Sep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "      <td>West</td>\n",
       "      <td>020A</td>\n",
       "      <td>276109</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Black</td>\n",
       "      <td>Parking lot/garage</td>\n",
       "      <td>Jul to Sep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AR0010200</td>\n",
       "      <td>STUTTGART</td>\n",
       "      <td>AR</td>\n",
       "      <td>South</td>\n",
       "      <td>030E</td>\n",
       "      <td>9467</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Black</td>\n",
       "      <td>Grocery/supermarket</td>\n",
       "      <td>Jul to Sep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7158</td>\n",
       "      <td>WV0410100</td>\n",
       "      <td>BECKLEY</td>\n",
       "      <td>WV</td>\n",
       "      <td>South</td>\n",
       "      <td>435S</td>\n",
       "      <td>17008</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Black</td>\n",
       "      <td>Parking lot/garage</td>\n",
       "      <td>Oct to Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7159</td>\n",
       "      <td>WV0540000</td>\n",
       "      <td>PARKERSBURG</td>\n",
       "      <td>WV</td>\n",
       "      <td>South</td>\n",
       "      <td>435S</td>\n",
       "      <td>41261</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Black</td>\n",
       "      <td>Highway/road/alley</td>\n",
       "      <td>Apr to Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7160</td>\n",
       "      <td>WY0090100</td>\n",
       "      <td>THERMOPOLIS</td>\n",
       "      <td>WY</td>\n",
       "      <td>West</td>\n",
       "      <td>450A</td>\n",
       "      <td>2969</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Am Indian</td>\n",
       "      <td>Drug store/dr office/hosp</td>\n",
       "      <td>Jan to Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7161</td>\n",
       "      <td>WY0150000</td>\n",
       "      <td>CODY</td>\n",
       "      <td>WY</td>\n",
       "      <td>West</td>\n",
       "      <td>450A</td>\n",
       "      <td>12283</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Other Religion</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>Jan to Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7162</td>\n",
       "      <td>WY0180000</td>\n",
       "      <td>PINEDALE</td>\n",
       "      <td>WY</td>\n",
       "      <td>West</td>\n",
       "      <td>450A</td>\n",
       "      <td>6690</td>\n",
       "      <td>2005</td>\n",
       "      <td>Anti-Female Homosexual</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>Apr to Jun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7163 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ORI         CITY STATECOD REGION JUDDIST    POP1  MASTERYR  \\\n",
       "0     AK0010100    ANCHORAGE       AK   West    020A  276109      2005   \n",
       "1     AK0010100    ANCHORAGE       AK   West    020A  276109      2005   \n",
       "2     AK0010100    ANCHORAGE       AK   West    020A  276109      2005   \n",
       "3     AK0010100    ANCHORAGE       AK   West    020A  276109      2005   \n",
       "4     AR0010200    STUTTGART       AR  South    030E    9467      2005   \n",
       "...         ...          ...      ...    ...     ...     ...       ...   \n",
       "7158  WV0410100      BECKLEY       WV  South    435S   17008      2005   \n",
       "7159  WV0540000  PARKERSBURG       WV  South    435S   41261      2005   \n",
       "7160  WY0090100  THERMOPOLIS       WY   West    450A    2969      2005   \n",
       "7161  WY0150000         CODY       WY   West    450A   12283      2005   \n",
       "7162  WY0180000     PINEDALE       WY   West    450A    6690      2005   \n",
       "\n",
       "                     BIASMO1                    LOCCOD1     QUARTER  \n",
       "0                 Anti-Black         Highway/road/alley  Apr to Jun  \n",
       "1             Anti-Am Indian              Other/unknown  Jul to Sep  \n",
       "2             Anti-Am Indian         Highway/road/alley  Jul to Sep  \n",
       "3                 Anti-Black         Parking lot/garage  Jul to Sep  \n",
       "4                 Anti-Black        Grocery/supermarket  Jul to Sep  \n",
       "...                      ...                        ...         ...  \n",
       "7158              Anti-Black         Parking lot/garage  Oct to Dec  \n",
       "7159              Anti-Black         Highway/road/alley  Apr to Jun  \n",
       "7160          Anti-Am Indian  Drug store/dr office/hosp  Jan to Mar  \n",
       "7161     Anti-Other Religion             Residence/home  Jan to Mar  \n",
       "7162  Anti-Female Homosexual             Residence/home  Apr to Jun  \n",
       "\n",
       "[7163 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_comp = df['BIASMO1'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_race = ['Anti-Black',\n",
    "            'Anti-Am Indian',\n",
    "            'Anti-Asian',\n",
    "            'Anti-White',\n",
    "            'Anti-Other ethnicity',\n",
    "            'Anti-Multi-Racial',\n",
    "            'Anti-Hispanic']\n",
    "\n",
    "anti_sexual = ['Anti-Male Homosexual',\n",
    "                'Anti-Bisexual',\n",
    "                'Anti-Homosexual (both)',\n",
    "                'Anti-Heterosexual',\n",
    "                'Anti-Female Homosexual']\n",
    "\n",
    "anti_religion = ['Anti-Catholic',\n",
    "                'Anti-Islamic',\n",
    "                'Anti-Protestant',\n",
    "                'Anti-Jewish',\n",
    "                'Anti-Atheism/Agnosticism',\n",
    "                'Anti-Multi-Religious',\n",
    "                'Anti-Other Religion']\n",
    "\n",
    "anti_handicap = ['Anti-Physical Disability', 'Anti-Mental Disability']\n",
    "\n",
    "df['BIASMO1'] = df['BIASMO1'].replace(dict.fromkeys(anti_race,'Anti-Race'))\n",
    "df['BIASMO1'] = df['BIASMO1'].replace(dict.fromkeys(anti_sexual,'Anti-Sexual Orientation'))\n",
    "df['BIASMO1'] = df['BIASMO1'].replace(dict.fromkeys(anti_religion,'Anti-Religion'))\n",
    "df['BIASMO1'] = df['BIASMO1'].replace(dict.fromkeys(anti_handicap,'Anti-Disability'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_stata('2006_ML/DS0002/22406-0002-Data.dta', columns=['ORI','CITY','STATECOD','REGION','JUDDIST','POP1','MASTERYR','BIASMO1','LOCCOD1','QUARTER'])\n",
    "df2 = df2.dropna(axis = 1)\n",
    "df2['BIASMO1'] = df2['BIASMO1'].replace(dict.fromkeys(anti_race,'Anti-Race'))\n",
    "df2['BIASMO1'] = df2['BIASMO1'].replace(dict.fromkeys(anti_sexual,'Anti-Sexual Orientation'))\n",
    "df2['BIASMO1'] = df2['BIASMO1'].replace(dict.fromkeys(anti_religion,'Anti-Religion'))\n",
    "df2['BIASMO1'] = df2['BIASMO1'].replace(dict.fromkeys(anti_handicap,'Anti-Disability'))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_stata('2007_ML/DS0002/25107-0002-Data.dta', columns=['ORI','CITY','STATECOD','REGION','JUDDIST','POP1','MASTERYR','BIASMO1','LOCCOD1','QUARTER'])\n",
    "df3 = df3.dropna(axis = 1)\n",
    "df3['BIASMO1'] = df3['BIASMO1'].replace(dict.fromkeys(anti_race,'Anti-Race'))\n",
    "df3['BIASMO1'] = df3['BIASMO1'].replace(dict.fromkeys(anti_sexual,'Anti-Sexual Orientation'))\n",
    "df3['BIASMO1'] = df3['BIASMO1'].replace(dict.fromkeys(anti_religion,'Anti-Religion'))\n",
    "df3['BIASMO1'] = df3['BIASMO1'].replace(dict.fromkeys(anti_handicap,'Anti-Disability'))\n",
    "df3['BIASMO1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_stata('2008_ML/DS0002/27645-0002-Data.dta', columns=['ORI','CITY','STATECOD','REGION','JUDDIST','POP1','MASTERYR','BIASMO1','LOCCOD1','QUARTER'])\n",
    "df4 = df4.dropna(axis = 1)\n",
    "df4['BIASMO1'] = df4['BIASMO1'].replace(dict.fromkeys(anti_race,'Anti-Race'))\n",
    "df4['BIASMO1'] = df4['BIASMO1'].replace(dict.fromkeys(anti_sexual,'Anti-Sexual Orientation'))\n",
    "df4['BIASMO1'] = df4['BIASMO1'].replace(dict.fromkeys(anti_religion,'Anti-Religion'))\n",
    "df4['BIASMO1'] = df4['BIASMO1'].replace(dict.fromkeys(anti_handicap,'Anti-Disability'))\n",
    "df4['BIASMO1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_stata('2009_ML/DS0002/30764-0002-Data.dta', columns=['ORI','CITY','STATECOD','REGION','JUDDIST','POP1','MASTERYR','BIASMO1','LOCCOD1','QUARTER'])\n",
    "df5 = df5.dropna(axis = 1)\n",
    "df5['BIASMO1'] = df5['BIASMO1'].replace(dict.fromkeys(anti_race,'Anti-Race'))\n",
    "df5['BIASMO1'] = df5['BIASMO1'].replace(dict.fromkeys(anti_sexual,'Anti-Sexual Orientation'))\n",
    "df5['BIASMO1'] = df5['BIASMO1'].replace(dict.fromkeys(anti_religion,'Anti-Religion'))\n",
    "df5['BIASMO1'] = df5['BIASMO1'].replace(dict.fromkeys(anti_handicap,'Anti-Disability'))\n",
    "df5['BIASMO1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df,df2,df3,df4,df5]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class StdScalerByGroup(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> std.grps_ is not None\n",
    "        True\n",
    "        \"\"\"\n",
    "        # X may not be a pandas dataframe (e.g. a np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        mean_df = df.groupby(df.columns[0]).mean()\n",
    "        std_df = df.groupby(df.columns[0]).std()\n",
    "        \n",
    "        # A dictionary of means/standard-deviations for each column, for each group.\n",
    "        self.grps_ = [mean_df, std_df]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> out = std.transform(X)\n",
    "        >>> out.shape == (4, 2)\n",
    "        True\n",
    "        >>> np.isclose(out.abs(), 0.707107, atol=0.001).all().all()\n",
    "        True\n",
    "        \"\"\"\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "        \n",
    "        # X may not be a dataframe (e.g. np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        \n",
    "        grouped_mean = self.grps_[0]\n",
    "        grouped_std = self.grps_[1]\n",
    "        numerator = (df.set_index(df.columns[0])-grouped_mean.reindex(df[df.columns[0]])).reset_index()\n",
    "        z_score = (numerator.set_index(df.columns[0])/grouped_std.reindex(df[df.columns[0]])).reset_index()\n",
    "        return z_score.set_index(z_score.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(titanic):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'titanic.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl = titanic_model(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> from sklearn.base import BaseEstimator\n",
    "    >>> isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "    True\n",
    "    >>> preds = pl.predict(data.drop('Survived', axis=1))\n",
    "    >>> ((preds == 0)|(preds == 1)).all()\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.datasets import load_iris\n",
    "    \n",
    "    def prefix(col):\n",
    "        col = col.iloc[:,0]\n",
    "        return np.array(col.str.split().str[:1].str[0]).reshape(-1,1)\n",
    "    \n",
    "    #X, y = load_iris(return_X_y=True)\n",
    "    x_value = titanic.drop(columns=['BIAS MOTIVATION'])\n",
    "    y_value = titanic['BIAS MOTIVATION']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_value, y_value, test_size=0.25)\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    #name_feat = ['Name']\n",
    "    #name_tran = Pipeline([\n",
    "        #('title', FunctionTransformer(prefix, validate=False)),\n",
    "        #('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    #])\n",
    "\n",
    "    #p_feat = ['Pclass', 'Age']\n",
    "    #p_tran = Pipeline([\n",
    "    #    ('standard unit', StdScalerByGroup())\n",
    "    #])\n",
    "\n",
    "    #cat_feat = ['ORI','CITY','STATECOD','REGION','JUDDIST','POP1','MASTERYR','LOCCOD1','QUARTER']\n",
    "    cat_feat = ['AGENCY IDENTIFIER','CITY','STATE','REGION','JUDICIAL DISTRICT','POPULATION',\\\n",
    "                'YEAR','QUARTER','LOCATION']\n",
    "    cat_tran = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    pre = ColumnTransformer(transformers=[('cat', cat_tran, cat_feat)], remainder='passthrough')\n",
    "\n",
    "    comb = Pipeline([('preprocessor', pre), ('rfc', RandomForestClassifier(n_estimators=180,min_samples_leaf=3))])\n",
    "    #comb = Pipeline([('preprocessor', pre), ('gnb', GaussianNB())])\n",
    "    comb.fit(x_train,y_train)\n",
    "    return comb, x_test, y_test\n",
    "    #gnb = GaussianNB()\n",
    "    #y_pred = gnb.fit(x_train, y_train).predict(x_test)\n",
    "    #return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDatatables = pd.read_csv('combinedDatatables.csv')\n",
    "combinedDatatables[combinedDatatables['JUDICIAL DISTRICT'].isna()]#.value_counts() #= combinedDatatables.dropna(axis = 1)\n",
    "combinedDatatables[combinedDatatables['BIAS MOTIVATION'].isna()]['YEAR'].value_counts()\n",
    "combinedDatatables = combinedDatatables.dropna()\n",
    "combinedDatatables.groupby('YEAR')['BIAS MOTIVATION'].value_counts()#.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1,x_test,y_test = titanic_model(combinedDatatables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = p1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.score(combinedDatatables.drop('BIAS MOTIVATION', axis=1),combinedDatatables['BIAS MOTIVATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2,x2_test,y2_test = titanic_model(combinedDatatables)\n",
    "y2_pred = p2.predict(x2_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
