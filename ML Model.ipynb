{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = combined_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGENCY IDENTIFIER</th>\n",
       "      <th>BIAS MOTIVATION</th>\n",
       "      <th>CITY</th>\n",
       "      <th>JUDICIAL DISTRICT</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>REGION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>020A</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>260900</td>\n",
       "      <td>Jul to Sep</td>\n",
       "      <td>West</td>\n",
       "      <td>AK</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>020A</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>260900</td>\n",
       "      <td>Jul to Sep</td>\n",
       "      <td>West</td>\n",
       "      <td>AK</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>020A</td>\n",
       "      <td>Highway/road/alley</td>\n",
       "      <td>260900</td>\n",
       "      <td>Jan to Mar</td>\n",
       "      <td>West</td>\n",
       "      <td>AK</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AK0010100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>020A</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>260900</td>\n",
       "      <td>Jan to Mar</td>\n",
       "      <td>West</td>\n",
       "      <td>AK</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AR0080300</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>GREEN FOREST</td>\n",
       "      <td>035W</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>2785</td>\n",
       "      <td>Jul to Sep</td>\n",
       "      <td>South</td>\n",
       "      <td>AR</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120250</td>\n",
       "      <td>WV0490100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>BUCKHANNON</td>\n",
       "      <td>430N</td>\n",
       "      <td>Bar/nightclub</td>\n",
       "      <td>5662</td>\n",
       "      <td>Oct to Dec</td>\n",
       "      <td>South</td>\n",
       "      <td>WV</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120251</td>\n",
       "      <td>WV0540100</td>\n",
       "      <td>Anti-Sexual Orientation</td>\n",
       "      <td>PARKERSBURG</td>\n",
       "      <td>435S</td>\n",
       "      <td>Highway/road/alley</td>\n",
       "      <td>30913</td>\n",
       "      <td>Jan to Mar</td>\n",
       "      <td>South</td>\n",
       "      <td>WV</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120252</td>\n",
       "      <td>WY0030100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>GILLETTE</td>\n",
       "      <td>450A</td>\n",
       "      <td>School--elementary/secondary</td>\n",
       "      <td>33218</td>\n",
       "      <td>Apr to Jun</td>\n",
       "      <td>West</td>\n",
       "      <td>WY</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120253</td>\n",
       "      <td>WY0030100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>GILLETTE</td>\n",
       "      <td>450A</td>\n",
       "      <td>School--elementary/secondary</td>\n",
       "      <td>33218</td>\n",
       "      <td>Apr to Jun</td>\n",
       "      <td>West</td>\n",
       "      <td>WY</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120254</td>\n",
       "      <td>WY0030100</td>\n",
       "      <td>Anti-Race</td>\n",
       "      <td>GILLETTE</td>\n",
       "      <td>450A</td>\n",
       "      <td>Residence/home</td>\n",
       "      <td>33218</td>\n",
       "      <td>Oct to Dec</td>\n",
       "      <td>West</td>\n",
       "      <td>WY</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119845 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGENCY IDENTIFIER          BIAS MOTIVATION          CITY  \\\n",
       "0              AK0010100                Anti-Race     ANCHORAGE   \n",
       "1              AK0010100                Anti-Race     ANCHORAGE   \n",
       "2              AK0010100                Anti-Race     ANCHORAGE   \n",
       "3              AK0010100                Anti-Race     ANCHORAGE   \n",
       "4              AR0080300                Anti-Race  GREEN FOREST   \n",
       "...                  ...                      ...           ...   \n",
       "120250         WV0490100                Anti-Race    BUCKHANNON   \n",
       "120251         WV0540100  Anti-Sexual Orientation   PARKERSBURG   \n",
       "120252         WY0030100                Anti-Race      GILLETTE   \n",
       "120253         WY0030100                Anti-Race      GILLETTE   \n",
       "120254         WY0030100                Anti-Race      GILLETTE   \n",
       "\n",
       "       JUDICIAL DISTRICT                      LOCATION  POPULATION  \\\n",
       "0                   020A                Residence/home      260900   \n",
       "1                   020A                Residence/home      260900   \n",
       "2                   020A            Highway/road/alley      260900   \n",
       "3                   020A                Residence/home      260900   \n",
       "4                   035W                Residence/home        2785   \n",
       "...                  ...                           ...         ...   \n",
       "120250              430N                 Bar/nightclub        5662   \n",
       "120251              435S            Highway/road/alley       30913   \n",
       "120252              450A  School--elementary/secondary       33218   \n",
       "120253              450A  School--elementary/secondary       33218   \n",
       "120254              450A                Residence/home       33218   \n",
       "\n",
       "           QUARTER REGION STATE  YEAR  \n",
       "0       Jul to Sep   West    AK  2000  \n",
       "1       Jul to Sep   West    AK  2000  \n",
       "2       Jan to Mar   West    AK  2000  \n",
       "3       Jan to Mar   West    AK  2000  \n",
       "4       Jul to Sep  South    AR  2000  \n",
       "...            ...    ...   ...   ...  \n",
       "120250  Oct to Dec  South    WV  2016  \n",
       "120251  Jan to Mar  South    WV  2016  \n",
       "120252  Apr to Jun   West    WY  2016  \n",
       "120253  Apr to Jun   West    WY  2016  \n",
       "120254  Oct to Dec   West    WY  2016  \n",
       "\n",
       "[119845 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdScalerByGroup(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> std.grps_ is not None\n",
    "        True\n",
    "        \"\"\"\n",
    "        # X may not be a pandas dataframe (e.g. a np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        mean_df = df.groupby(df.columns[0]).mean()\n",
    "        std_df = df.groupby(df.columns[0]).std()\n",
    "        \n",
    "        # A dictionary of means/standard-deviations for each column, for each group.\n",
    "        self.grps_ = [mean_df, std_df]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> out = std.transform(X)\n",
    "        >>> out.shape == (4, 2)\n",
    "        True\n",
    "        >>> np.isclose(out.abs(), 0.707107, atol=0.001).all().all()\n",
    "        True\n",
    "        \"\"\"\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "        \n",
    "        # X may not be a dataframe (e.g. np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "        \n",
    "        grouped_mean = self.grps_[0]\n",
    "        grouped_std = self.grps_[1]\n",
    "        numerator = (df.set_index(df.columns[0])-grouped_mean.reindex(df[df.columns[0]])).reset_index()\n",
    "        z_score = (numerator.set_index(df.columns[0])/grouped_std.reindex(df[df.columns[0]])).reset_index()\n",
    "        return z_score.set_index(z_score.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value = temp.drop(columns=['BIAS MOTIVATION'])\n",
    "y_value = temp['BIAS MOTIVATION']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_value, y_value, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc(dataset):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'titanic.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl = titanic_model(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> from sklearn.base import BaseEstimator\n",
    "    >>> isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "    True\n",
    "    >>> preds = pl.predict(data.drop('Survived', axis=1))\n",
    "    >>> ((preds == 0)|(preds == 1)).all()\n",
    "    True\n",
    "    \"\"\"    \n",
    "    def prefix(col):\n",
    "        col = col.iloc[:,0]\n",
    "        return np.array(col.str.split().str[:1].str[0]).reshape(-1,1)\n",
    "\n",
    "    cat_feat = ['AGENCY IDENTIFIER', 'CITY', 'JUDICIAL DISTRICT',\n",
    "       'LOCATION', 'POPULATION', 'QUARTER', 'REGION', 'STATE', 'YEAR']\n",
    "    cat_tran = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    pre = ColumnTransformer(transformers=[('cat', cat_tran, cat_feat)], remainder='passthrough')\n",
    "\n",
    "    comb = Pipeline([('preprocessor', pre), ('rfc', RandomForestClassifier(n_estimators=180,min_samples_leaf=3))])\n",
    "    comb.fit(x_train,y_train)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_list = []\n",
    "for i in range(10): \n",
    "    p1 = rfc(temp)\n",
    "    rfc_list.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "for i in range(len(rfc_list)): \n",
    "    preds = rfc_list[i].predict(x_test)\n",
    "    preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rfc = []\n",
    "for i in range(len(preds_list)): \n",
    "    accuracy_rfc.append(metrics.accuracy_score(y_test, preds_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662973099259062"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rfc = np.sum(accuracy_rfc)/10\n",
    "mean_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_rfc = []\n",
    "for i in range(len(preds_list)): \n",
    "    random_forest = pd.Series(preds_list[i]).value_counts()\n",
    "    types_rfc.append(random_forest/random_forest.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_rfc = types_rfc[0]\n",
    "for i in range(1, len(types_rfc)): \n",
    "    overall_rfc += types_rfc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anti-Race                  0.906488\n",
       "Anti-Religion              0.083462\n",
       "Anti-Sexual Orientation    0.009248\n",
       "Anti-Disability            0.000801\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_rfc/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knc(dataset):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'titanic.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl = titanic_model(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> from sklearn.base import BaseEstimator\n",
    "    >>> isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "    True\n",
    "    >>> preds = pl.predict(data.drop('Survived', axis=1))\n",
    "    >>> ((preds == 0)|(preds == 1)).all()\n",
    "    True\n",
    "    \"\"\"    \n",
    "    def prefix(col):\n",
    "        col = col.iloc[:,0]\n",
    "        return np.array(col.str.split().str[:1].str[0]).reshape(-1,1)\n",
    "\n",
    "    cat_feat = ['AGENCY IDENTIFIER', 'CITY', 'JUDICIAL DISTRICT',\n",
    "       'LOCATION', 'POPULATION', 'QUARTER', 'REGION', 'STATE', 'YEAR']\n",
    "    cat_tran = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    pre = ColumnTransformer(transformers=[('cat', cat_tran, cat_feat)], remainder='passthrough')\n",
    "\n",
    "    comb = Pipeline([('preprocessor', pre), ('rfc', KNeighborsClassifier())])\n",
    "    comb.fit(x_train,y_train)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_list = []\n",
    "for i in range(10): \n",
    "    p2 = knc(temp)\n",
    "    knc_list.append(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list2 = []\n",
    "for i in range(len(knc_list)): \n",
    "    preds = knc_list[i].predict(x_test)\n",
    "    preds_list2.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_knc = []\n",
    "for i in range(len(preds_list2)): \n",
    "    accuracy_knc.append(metrics.accuracy_score(y_test, preds_list2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.633168680328416"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_knc = np.sum(accuracy_knc)/10\n",
    "mean_knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_knc = []\n",
    "for i in range(len(preds_list2)): \n",
    "    random_forest = pd.Series(preds_list2[i]).value_counts()\n",
    "    types_knc.append(random_forest/random_forest.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anti-Race                  0.796776\n",
       "Anti-Religion              0.124491\n",
       "Anti-Sexual Orientation    0.075529\n",
       "Anti-Disability            0.002503\n",
       "Anti-Gender                0.000701\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_knc = types_knc[0]\n",
    "for i in range(1, len(types_knc)): \n",
    "    overall_knc += types_knc[i]\n",
    "overall_knc/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
